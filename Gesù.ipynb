{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Self-supervised-trial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboTuan/ML_DL_Project/blob/master/Ges%C3%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLYoVb2SQnG0",
        "cellView": "both",
        "outputId": "ef9bfbc2-f1b7-47e6-b370-198f8f3a6574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#@title\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.autograd import Function\n",
        "import torchvision\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import pandas.util.testing as tm\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZVmFAwkQ0AS",
        "outputId": "a02cc579-9e90-42d0-b7b8-90e8d228d838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzqpeOqKQ0Vt"
      },
      "source": [
        "!unzip -q \"./drive/My Drive/Copia di GTEA61.zip\"\n",
        "!rm -rf \"./__MACOSX\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihz9gTQEQ0Z3"
      },
      "source": [
        "!rm -rf \"./ML_DL_Project/\"\n",
        "#!rm -rf \"./out_dir/\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKvNku7pQ0cp",
        "outputId": "351b66dd-4d00-4a4c-cd43-f67146a2a609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "import os \n",
        "if not os.path.isdir('./ML_DL_Project'):\n",
        "  !git clone https://github.com/RoboTuan/ML_DL_Project.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_DL_Project'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 340 (delta 74), reused 60 (delta 32), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (340/340), 89.23 MiB | 13.85 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-6YG3acQ0g3",
        "outputId": "078c9e69-d3d6-4ac2-c822-211aa3df4389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "base_dataset = \"./GTEA61\"\n",
        "\n",
        "if not os.path.isdir('./GTEA61_val'):\n",
        "  os.makedirs(\"./GTEA61_val\")\n",
        "  os.makedirs(\"./GTEA61_val/flow_x_processed\")\n",
        "  os.makedirs(\"./GTEA61_val/flow_y_processed\")\n",
        "  os.makedirs(\"./GTEA61_val/processed_frames2\")\n",
        "  pass\n",
        "\n",
        "\n",
        "for directory in sorted(os.listdir(base_dataset)):\n",
        "  if not directory.startswith('.'):\n",
        "    directory_path = os.path.join(base_dataset, directory)\n",
        "    new_directory_path = os.path.join(\"./GTEA61_val\", directory)\n",
        "\n",
        "    for user in sorted(os.listdir(directory_path)):\n",
        "      if not user.startswith('.') and user == \"S2\":\n",
        "        current_folder = os.path.join(directory_path, user)\n",
        "        !cp -r \"{current_folder}\" \"{new_directory_path}\"\n",
        "        !rm -rf \"{current_folder}\"\n",
        "        print(current_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./GTEA61/flow_x_processed/S2\n",
            "./GTEA61/flow_y_processed/S2\n",
            "./GTEA61/processed_frames2/S2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nepLRofOQ0ji"
      },
      "source": [
        "# Se scritti uguali ai parametri della funzione può venire None come risultato\n",
        "# per questo SEQLEN è maiuscolo \n",
        "SEQLEN = 7\n",
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "num_classes = 61\n",
        "#STAGE = None\n",
        "train_data_dir = \"./GTEA61\"\n",
        "val_data_dir = \"./GTEA61_val\"\n",
        "#stage1_dict = None\n",
        "out_dir = \".out_dir\"\n",
        "trainBatchSize = 32\n",
        "valBatchSize = 64\n",
        "numEpochs1 = 3\n",
        "numEpochs2 = 3\n",
        "lr1 = 1e-3\n",
        "lr2 = 1e-4\n",
        "decay_factor = 0.1\n",
        "decay_step1 = [25, 75, 150]\n",
        "decay_step2 = [25, 75]\n",
        "#Boh?!\n",
        "memSize = 512\n",
        "alpha=1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZoYPO1hQ0o5"
      },
      "source": [
        "#!rm -rf \"ML_DL_Project\"\n",
        "#!rm -rf \"./GTEA61\"\n",
        "#!rm -rf \"./GTEA61_val\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrGDU3ojQ0uu"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "# This is without attention, we must address this better\n",
        "#from ML_DL_Project.Scripts.convLSTMmodel import *\n",
        "from ML_DL_Project.Scripts.SelfSupObjectAttentionModelConvLSTM import *\n",
        "from ML_DL_Project.Scripts.RegObjectAttentionModelConvLSTM import *\n",
        "from ML_DL_Project.Scripts.spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from ML_DL_Project.Scripts.resnetMod import *\n",
        "#from ML_DL_Project.Scripts.makeDatasetRGB import *\n",
        "from ML_DL_Project.Scripts.makeMmaps import *\n",
        "#Prende il makeDataset dell'ultimo script importato\n",
        "import argparse\n",
        "import sys"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec7hvOY2UjYG"
      },
      "source": [
        "!rm -rf \"./out_dir\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51H5bheaAx2I"
      },
      "source": [
        "# Data loader\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256),\n",
        "                             RandomHorizontalFlip(), \n",
        "                             MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), \n",
        "                             normalize])\n",
        "\n",
        "vid_seq_train = makeDataset(train_data_dir, spatial_transform=spatial_transform, seqLen=SEQLEN, fmt='.png')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "if val_data_dir is not None:\n",
        "  vid_seq_val = makeDataset(val_data_dir,spatial_transform = Compose([Scale(256),\n",
        "                                                                    CenterCrop(224),\n",
        "                                                                    ToTensor(),\n",
        "                                                                    normalize]),\n",
        "                            seqLen=SEQLEN, fmt='.png')\n",
        "\n",
        "  val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize, shuffle=False, num_workers=2, pin_memory=True)\n",
        "  valInstances = vid_seq_val.__len__()\n",
        "\n",
        "\n",
        "trainInstances = vid_seq_train.__len__()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFrMnCz_A8Al",
        "outputId": "7a30d437-cff8-4b85-907f-a94eaddd9f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for seqImages, seqMaps, labels in train_loader:\n",
        "  print(f\"Batch size: {len(seqImages)}\")\n",
        "  #Make dataset restituisce una sequenza di immagini e di mappe\n",
        "  print(f\"Batch size: {len(maps)}\")\n",
        "  print(f\"Number of frames selected: {len(seqImages[0])}\")\n",
        "  print(f\"Number of frames selected maps: {len(seqMaps[0])}\")\n",
        "\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch size: 32\n",
            "Batch size: 32\n",
            "Number of frames selected: 7\n",
            "Number of frames selected maps: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCaLyHOADtg"
      },
      "source": [
        "import torch\n",
        "import ML_DL_Project.Scripts.resnetMod\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from ML_DL_Project.Scripts.MyConvLSTMCell import *\n",
        "\n",
        "class Print(nn.Module):\n",
        "    def forward(self, x):\n",
        "        print(x.size())\n",
        "        return x\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class attentionModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512):\n",
        "        super(attentionModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnetMod.resnet34(True, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "\n",
        "        #Secondary task branch\n",
        "        self.mmapPredictor = nn.Sequential()\n",
        "        self.mmapPredictor.add_module('mmap_relu',nn.ReLU(True))\n",
        "        self.mmapPredictor.add_module('convolution', nn.Conv2d(512, 100, kernel_size=1))\n",
        "        self.mmapPredictor.add_module('flatten',Flatten())\n",
        "        self.mmapPredictor.add_module('fc_2',nn.Linear(100*7*7,2*7*7))\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputVariable):\n",
        "        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n",
        "                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n",
        "        \n",
        "        for t in range(inputVariable.size(0)):\n",
        "            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n",
        "            bz, nc, h, w = feature_conv.size()\n",
        "            feature_conv1 = feature_conv.view(bz, nc, h*w)\n",
        "            \n",
        "            probs, idxs = logit.sort(1, True)\n",
        "            class_idx = idxs[:, 0]\n",
        "            cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n",
        "            \n",
        "            attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n",
        "            attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n",
        "            attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n",
        "\n",
        "            #Prediction of the mmap\n",
        "            feature_conv2 = feature_conv.clone()\n",
        "            if t == 0:\n",
        "              map_predictions = self.mmapPredictor(feature_conv2)\n",
        "            else:\n",
        "              prediction = self.mmapPredictor(feature_conv2) #This can be feature_conv\n",
        "              map_predictions = torch.cat([map_predictions,prediction],dim=0)\n",
        "\n",
        "            state = self.lstm_cell(attentionFeat, state)\n",
        "        \n",
        "        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "        feats = self.classifier(feats1)\n",
        "        return feats, feats1, map_predictions#Makes the list a stack"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnsYtNDOC4Mi"
      },
      "source": [
        "train_params = []\n",
        "model = attentionModel(num_classes=num_classes, mem_size=memSize)\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "for params in model.lstm_cell.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "model.lstm_cell.train(True)\n",
        "\n",
        "model.classifier.train(True)\n",
        "model.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n",
        "\n",
        "optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step1,\n",
        "                                                           gamma=decay_factor)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQ8hcw88x_I",
        "outputId": "971e5791-d8be-4a5b-8dce-8bba158b5954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "attentionModel(\n",
              "  (resNet): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (5): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  )\n",
              "  (lstm_cell): MyConvLSTMCell(\n",
              "    (conv_i_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv_i_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (conv_f_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv_f_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (conv_c_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv_c_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (conv_o_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv_o_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "  (dropout): Dropout(p=0.7, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=61, bias=True)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.7, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=61, bias=True)\n",
              "  )\n",
              "  (mmapPredictor): Sequential(\n",
              "    (mmap_relu): ReLU(inplace=True)\n",
              "    (convolution): Conv2d(512, 100, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (flatten): Flatten()\n",
              "    (fc_2): Linear(in_features=4900, out_features=98, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoGca_3i-h7n",
        "outputId": "6011d55a-ddfe-4525-87ef-28c5fc2410e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "valDatasetDir = val_data_dir\n",
        "\n",
        "train_iter = 0\n",
        "min_accuracy = 0\n",
        "for epoch in range(numEpochs1):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    mmap_loss = 0\n",
        "    trainSamples = 0\n",
        "    iterPerEpoch = 0\n",
        "    \n",
        "    model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    #for i, (inputs, targets) in enumerate(train_loader):\n",
        "    for inputs, inputMmap, targets in train_loader:\n",
        "        train_iter += 1\n",
        "        iterPerEpoch += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "\n",
        "        inputMmap = inputMmap.cuda()\n",
        "        \n",
        "        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "        labelVariable = Variable(targets.cuda())\n",
        "        trainSamples += inputs.size(0)\n",
        "        \n",
        "        output_label, _ , mmapPrediction = model(inputVariable)\n",
        "\n",
        "        mmapPrediction = mmapPrediction.view(-1,2)         \n",
        "        inputMmap = torch.reshape(inputMmap, (-1,)) #.long()\n",
        "        inputMmap = torch.round(inputMmap).long() #making things black and white again\n",
        "        \n",
        "        \n",
        "        #print(mmapPrediction.size())\n",
        "        #print(inputMmap.size())\n",
        "        #print(mmapPrediction)\n",
        "        #print(inputMmap)\n",
        "        #sys.exit()\n",
        "\n",
        "        loss2 = alpha*loss_fn(mmapPrediction,inputMmap)\n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        #Weighting the loss of the ss task\n",
        "        #by multiplying it by alpha\n",
        "        total_loss = loss  + loss2\n",
        "        total_loss.backward()\n",
        "        \n",
        "        optimizer_fn.step()\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += (predicted == targets.cuda()).sum()\n",
        "        mmap_loss += loss2.item()\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "    avg_mmap_loss = mmap_loss / iterPerEpoch\n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = torch.true_divide(numCorrTrain , trainSamples) * 100\n",
        "\n",
        "    print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    print('Mmap loss after {} epoch = {}% '.format(epoch + 1, avg_mmap_loss))\n",
        "\n",
        "    \n",
        "    if valDatasetDir is not None:\n",
        "        model.train(False)\n",
        "        val_loss_epoch = 0\n",
        "        val_iter = 0\n",
        "        val_mmap_loss = 0\n",
        "        val_samples = 0\n",
        "        numCorr = 0\n",
        "        mmap_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #for j, (inputs, targets) in enumerate(val_loader):\n",
        "            for inputs, inputMmap, targets in val_loader:\n",
        "                val_iter += 1\n",
        "                val_samples += inputs.size(0)\n",
        "                inputMmap = inputMmap.cuda()\n",
        "\n",
        "                \n",
        "                inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "                labelVariable = Variable(targets.cuda(async=True))\n",
        "                #labelVariable = Variable(targets.cuda())\n",
        "                \n",
        "                output_label, _ , mmapPrediction = model(inputVariable)\n",
        "\n",
        "                mmapPrediction = mmapPrediction.view(-1,2)\n",
        "                inputMmap = torch.reshape(inputMmap, (-1,)) #.long()\n",
        "                inputMmap = torch.round(inputMmap).long()\n",
        "                loss2 = alpha*loss_fn(mmapPrediction,inputMmap)\n",
        "\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_epoch += val_loss.item()\n",
        "                val_mmap_loss += loss2.item()\n",
        "                \n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += (predicted == targets.cuda()).sum()\n",
        "\n",
        "        avg_mmap_val_loss = val_mmap_loss / val_iter\n",
        "        val_accuracy = torch.true_divide(numCorr , val_samples) * 100\n",
        "        avg_val_loss = val_loss_epoch / val_iter\n",
        "        \n",
        "        print('Val MMap Loss after {} epochs, loss = {}'.format(epoch + 1, avg_mmap_val_loss))\n",
        "        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "\n",
        "        #if val_accuracy > min_accuracy:\n",
        "            #save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n",
        "            #torch.save(model.state_dict(), save_path_model)\n",
        "            #min_accuracy = val_accuracy\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-0.2914, -0.4953],\n",
            "        [-0.0058,  0.1116],\n",
            "        [ 0.3728,  0.1879],\n",
            "        ...,\n",
            "        [-0.0748, -0.4045],\n",
            "        [ 0.7894,  0.3672],\n",
            "        [-0.1829, -0.2505]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-0.1900, -0.6978],\n",
            "        [ 0.6372,  0.5620],\n",
            "        [ 0.0993, -0.6612],\n",
            "        ...,\n",
            "        [-0.0764, -0.0697],\n",
            "        [ 0.6777,  0.1872],\n",
            "        [ 0.0274, -0.3665]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[ 0.1531,  0.0956],\n",
            "        [-0.6522, -0.4256],\n",
            "        [-0.0981,  0.7898],\n",
            "        ...,\n",
            "        [-0.5249,  0.4968],\n",
            "        [ 0.7937,  0.5105],\n",
            "        [ 0.0744,  0.2315]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-0.5003,  0.3058],\n",
            "        [ 0.8362, -0.0185],\n",
            "        [-0.1586,  0.4534],\n",
            "        ...,\n",
            "        [-0.4417, -0.0383],\n",
            "        [ 0.1916, -0.4923],\n",
            "        [ 0.5986, -0.8278]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-1.1794, -0.3339],\n",
            "        [ 0.4948,  0.6497],\n",
            "        [-0.1723,  0.1146],\n",
            "        ...,\n",
            "        [-0.7060,  0.2429],\n",
            "        [ 0.7474, -0.4074],\n",
            "        [ 0.1453, -0.6367]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-0.4601, -0.3483],\n",
            "        [ 0.1737,  0.1731],\n",
            "        [-0.1448,  0.3252],\n",
            "        ...,\n",
            "        [-0.3066, -0.4530],\n",
            "        [ 1.2421, -0.0140],\n",
            "        [-0.5259, -0.3124]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-0.1755, -0.4602],\n",
            "        [-0.0560,  0.0138],\n",
            "        [ 0.0588,  0.2684],\n",
            "        ...,\n",
            "        [-0.0593, -0.3601],\n",
            "        [ 1.2755,  0.4552],\n",
            "        [ 0.5061, -0.0697]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[ 0.6707, -0.3765],\n",
            "        [ 0.5414,  0.1271],\n",
            "        [-0.0059, -0.1567],\n",
            "        ...,\n",
            "        [-0.0730,  0.0132],\n",
            "        [ 0.4682,  0.5317],\n",
            "        [ 0.1722, -0.1846]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[ 0.3153, -0.7529],\n",
            "        [ 0.0809,  0.3583],\n",
            "        [-0.2397, -0.5956],\n",
            "        ...,\n",
            "        [-0.1717,  0.1954],\n",
            "        [ 1.0556, -0.0667],\n",
            "        [-0.0233, -0.0561]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([10976, 2])\n",
            "torch.Size([10976])\n",
            "tensor([[-0.9660, -0.4405],\n",
            "        [-0.4325, -0.6387],\n",
            "        [ 0.3305, -0.4741],\n",
            "        ...,\n",
            "        [-0.5640, -0.5989],\n",
            "        [ 0.8056,  0.5117],\n",
            "        [ 0.5497, -0.1643]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "torch.Size([7203, 2])\n",
            "torch.Size([7203])\n",
            "tensor([[-0.5825, -0.2397],\n",
            "        [ 0.9319,  0.5251],\n",
            "        [ 1.1366, -0.2082],\n",
            "        ...,\n",
            "        [ 0.1224, -0.2311],\n",
            "        [ 0.6105, -0.5115],\n",
            "        [ 0.1712, -0.0914]], device='cuda:0')\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
            "Train: Epoch = 1 | Loss = 4.046900900927457 | Accuracy = 6.744868278503418\n",
            "Mmap loss after 1 epoch = 0.7642495090311224% \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:82: UserWarning: This overload of cuda is deprecated:\n",
            "\tcuda(torch.device device, bool async, *, torch.memory_format memory_format)\n",
            "Consider using one of the following signatures instead:\n",
            "\tcuda(torch.device device, bool non_blocking, *, torch.memory_format memory_format) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val MMap Loss after 1 epochs, loss = 0.7899662554264069\n",
            "Val: Epoch = 1 | Loss 3.902999758720398 | Accuracy = 6.034482479095459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-aa673811aebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0msave_path_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_rgb_state_dict.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mmin_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_folder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A39o56KG_5OH"
      },
      "source": [
        "yolo = vid_seq_train.maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc5t4urMDVOC"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "\n",
        "from ML_DL_Project.Scripts.spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "normalize = Normalize(mean=mean, std=std)\n",
        "spatial_transform2 = Compose([Scale((7,7)), ToTensor()]) \n",
        "\n",
        "def listDirectory(path):\n",
        "  if os.path.isdir(path):\n",
        "    return os.listdir(path)\n",
        "  \n",
        "  return []\n",
        "\n",
        "def gen_split(root_dir, stackSize):\n",
        "    DatasetF = []\n",
        "    Labels = []\n",
        "    NumFrames = []\n",
        "    #The root directory should be processed frames/train or test\n",
        "    for dir_user in sorted(os.listdir(root_dir)):\n",
        "        class_id = 0\n",
        "        dir = os.path.join(root_dir, dir_user)\n",
        "        for target in sorted(os.listdir(dir)):\n",
        "            dir1 = os.path.join(dir, target)\n",
        "            insts = sorted(listDirectory(dir1))              \n",
        "            if insts != []:\n",
        "                for inst in insts:\n",
        "                    inst_dir = os.path.join(dir1,inst,'rgb')\n",
        "                    inst_dir2 = os.path.join(dir1,inst)\n",
        "                    numFrames = len(glob.glob1(inst_dir, '*.png'))\n",
        "\n",
        "                    if numFrames >= stackSize:\n",
        "                        DatasetF.append(inst_dir2)\n",
        "                        Labels.append(class_id)\n",
        "                        NumFrames.append(numFrames)\n",
        "                class_id += 1\n",
        "    bad_lab = [x for x in Labels if x>=61]\n",
        "    #print(f'Bad labels {bad_lab}')\n",
        "    return DatasetF, Labels, NumFrames\n",
        "\n",
        "\n",
        "class makeDatasetPedro(Dataset):\n",
        "    def __init__(self, root_dir, spatial_transform=None, sequence=False, stackSize=5,\n",
        "                 train=True, numSeg=5, fmt='.png', phase='train', seqLen = 25):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "\n",
        "        self.imagesF, self.labels, self.numFrames = gen_split(root_dir, stackSize)\n",
        "        self.spatial_transform = spatial_transform\n",
        "        self.train = train\n",
        "        self.numSeg = numSeg\n",
        "        self.sequence = sequence\n",
        "        self.stackSize = stackSize\n",
        "        self.fmt = fmt\n",
        "        self.phase = phase\n",
        "        self.seqLen = seqLen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagesF)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        vid_nameF = self.imagesF[idx]\n",
        "        label = self.labels[idx]\n",
        "        numFrame = self.numFrames[idx]\n",
        "        inpSeqSegs = []\n",
        "        self.spatial_transform.randomize_parameters()\n",
        "\n",
        "        inpSeqF = []\n",
        "        for i in np.linspace(1, numFrame, self.seqLen, endpoint=False):\n",
        "            fl_name = vid_nameF +  '/' + 'rgb' +'/' + 'rgb' + str(int(np.floor(i))).zfill(4) + self.fmt\n",
        "            img = Image.open(fl_name)\n",
        "            inpSeqF.append(self.spatial_transform(img.convert('RGB')))\n",
        "        inpSeqF = torch.stack(inpSeqF, 0)\n",
        "\n",
        "        #Adding the mmaps to the dataloader\n",
        "        inpSeqMmaps = []\n",
        "        try:\n",
        "          inpSeqMmaps = []\n",
        "          for i in np.linspace(1,numFrame, self.seqLen, endpoint=False):\n",
        "            fl_name = vid_nameF +  '/' + 'mmaps' +'/' + 'map' + str(int(np.floor(i))).zfill(4) + self.fmt\n",
        "            img = Image.open(fl_name)\n",
        "            inpSeqMmaps.append(spatial_transform2(img.convert('L')))\n",
        "        except:\n",
        "            inpSeqMmaps = []\n",
        "            for i in np.linspace(2,numFrame, self.seqLen, endpoint=False):\n",
        "              fl_name = vid_nameF +  '/' + 'mmaps' +'/' + 'map' + str(int(np.floor(i))).zfill(4) + self.fmt\n",
        "              img = Image.open(fl_name)\n",
        "              inpSeqMmaps.append(spatial_transform2(img.convert('L'))) #Grayscale\n",
        "  \n",
        "        inpSeqMmaps = torch.stack(inpSeqMmaps,0)\n",
        "\n",
        "        return inpSeqF, inpSeqMmaps ,label#, vid_nameF#, fl_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOfBEG27E2jX"
      },
      "source": [
        "!find ./GTEA61 -name .DS_Store -type f -delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uYva5n3De1W"
      },
      "source": [
        "pedro = makeDatasetPedro(\"./GTEA61/processed_frames2\", spatial_transform=spatial_transform, seqLen=SEQLEN, fmt='.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJMw5RpvFPTM",
        "outputId": "f19c331e-adbe-4121-9de7-169f805ed8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pedro.imagesF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./GTEA61/processed_frames2/S1/close_chocolate/1',\n",
              " './GTEA61/processed_frames2/S1/close_coffee/1',\n",
              " './GTEA61/processed_frames2/S1/close_coffee/2',\n",
              " './GTEA61/processed_frames2/S1/close_honey/1',\n",
              " './GTEA61/processed_frames2/S1/close_honey/2',\n",
              " './GTEA61/processed_frames2/S1/close_jam/1',\n",
              " './GTEA61/processed_frames2/S1/close_ketchup/1',\n",
              " './GTEA61/processed_frames2/S1/close_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S1/close_mustard/1',\n",
              " './GTEA61/processed_frames2/S1/close_mustard/2',\n",
              " './GTEA61/processed_frames2/S1/close_peanut/1',\n",
              " './GTEA61/processed_frames2/S1/close_peanut/2',\n",
              " './GTEA61/processed_frames2/S1/close_sugar/1',\n",
              " './GTEA61/processed_frames2/S1/close_sugar/2',\n",
              " './GTEA61/processed_frames2/S1/close_water/1',\n",
              " './GTEA61/processed_frames2/S1/close_water/2',\n",
              " './GTEA61/processed_frames2/S1/close_water/3',\n",
              " './GTEA61/processed_frames2/S1/fold_bread/1',\n",
              " './GTEA61/processed_frames2/S1/open_cheese/1',\n",
              " './GTEA61/processed_frames2/S1/open_chocolate/1',\n",
              " './GTEA61/processed_frames2/S1/open_coffee/1',\n",
              " './GTEA61/processed_frames2/S1/open_coffee/2',\n",
              " './GTEA61/processed_frames2/S1/open_honey/1',\n",
              " './GTEA61/processed_frames2/S1/open_honey/2',\n",
              " './GTEA61/processed_frames2/S1/open_jam/1',\n",
              " './GTEA61/processed_frames2/S1/open_ketchup/1',\n",
              " './GTEA61/processed_frames2/S1/open_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S1/open_mustard/1',\n",
              " './GTEA61/processed_frames2/S1/open_mustard/2',\n",
              " './GTEA61/processed_frames2/S1/open_peanut/1',\n",
              " './GTEA61/processed_frames2/S1/open_peanut/2',\n",
              " './GTEA61/processed_frames2/S1/open_sugar/1',\n",
              " './GTEA61/processed_frames2/S1/open_sugar/2',\n",
              " './GTEA61/processed_frames2/S1/open_tea/1',\n",
              " './GTEA61/processed_frames2/S1/open_water/1',\n",
              " './GTEA61/processed_frames2/S1/open_water/2',\n",
              " './GTEA61/processed_frames2/S1/open_water/3',\n",
              " './GTEA61/processed_frames2/S1/pour_chocolate,bread/1',\n",
              " './GTEA61/processed_frames2/S1/pour_coffee,spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S1/pour_coffee,spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S1/pour_coffee,spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S1/pour_coffee,spoon,cup/4',\n",
              " './GTEA61/processed_frames2/S1/pour_honey,bread/1',\n",
              " './GTEA61/processed_frames2/S1/pour_honey,cup/1',\n",
              " './GTEA61/processed_frames2/S1/pour_ketchup,hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S1/pour_mayonnaise,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S1/pour_mustard,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S1/pour_mustard,hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S1/pour_sugar,spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S1/pour_sugar,spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S1/pour_sugar,spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S1/pour_sugar,spoon,cup/4',\n",
              " './GTEA61/processed_frames2/S1/pour_water,cup/1',\n",
              " './GTEA61/processed_frames2/S1/pour_water,cup/2',\n",
              " './GTEA61/processed_frames2/S1/pour_water,cup/3',\n",
              " './GTEA61/processed_frames2/S1/put_bread,bread/1',\n",
              " './GTEA61/processed_frames2/S1/put_bread,bread/2',\n",
              " './GTEA61/processed_frames2/S1/put_bread,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S1/put_cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S1/put_hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S1/scoop_coffee,spoon/1',\n",
              " './GTEA61/processed_frames2/S1/scoop_coffee,spoon/2',\n",
              " './GTEA61/processed_frames2/S1/scoop_coffee,spoon/3',\n",
              " './GTEA61/processed_frames2/S1/scoop_coffee,spoon/4',\n",
              " './GTEA61/processed_frames2/S1/scoop_jam,spoon/1',\n",
              " './GTEA61/processed_frames2/S1/scoop_peanut,spoon/1',\n",
              " './GTEA61/processed_frames2/S1/scoop_peanut,spoon/2',\n",
              " './GTEA61/processed_frames2/S1/scoop_sugar,spoon/1',\n",
              " './GTEA61/processed_frames2/S1/scoop_sugar,spoon/2',\n",
              " './GTEA61/processed_frames2/S1/scoop_sugar,spoon/3',\n",
              " './GTEA61/processed_frames2/S1/scoop_sugar,spoon/4',\n",
              " './GTEA61/processed_frames2/S1/shake_tea,cup/1',\n",
              " './GTEA61/processed_frames2/S1/spread_jam,spoon,bread/1',\n",
              " './GTEA61/processed_frames2/S1/spread_peanut,spoon,bread/1',\n",
              " './GTEA61/processed_frames2/S1/spread_peanut,spoon,bread/2',\n",
              " './GTEA61/processed_frames2/S1/stir_spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S1/stir_spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S1/stir_spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S1/take_bread/1',\n",
              " './GTEA61/processed_frames2/S1/take_bread/2',\n",
              " './GTEA61/processed_frames2/S1/take_bread/3',\n",
              " './GTEA61/processed_frames2/S1/take_bread/4',\n",
              " './GTEA61/processed_frames2/S1/take_bread/5',\n",
              " './GTEA61/processed_frames2/S1/take_bread/6',\n",
              " './GTEA61/processed_frames2/S1/take_bread/7',\n",
              " './GTEA61/processed_frames2/S1/take_cheese/1',\n",
              " './GTEA61/processed_frames2/S1/take_chocolate/1',\n",
              " './GTEA61/processed_frames2/S1/take_coffee/1',\n",
              " './GTEA61/processed_frames2/S1/take_coffee/2',\n",
              " './GTEA61/processed_frames2/S1/take_cup/1',\n",
              " './GTEA61/processed_frames2/S1/take_cup/2',\n",
              " './GTEA61/processed_frames2/S1/take_cup/3',\n",
              " './GTEA61/processed_frames2/S1/take_honey/1',\n",
              " './GTEA61/processed_frames2/S1/take_honey/2',\n",
              " './GTEA61/processed_frames2/S1/take_honey/3',\n",
              " './GTEA61/processed_frames2/S1/take_hotdog/1',\n",
              " './GTEA61/processed_frames2/S1/take_jam/1',\n",
              " './GTEA61/processed_frames2/S1/take_ketchup/1',\n",
              " './GTEA61/processed_frames2/S1/take_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S1/take_mustard/1',\n",
              " './GTEA61/processed_frames2/S1/take_mustard/2',\n",
              " './GTEA61/processed_frames2/S1/take_peanut/1',\n",
              " './GTEA61/processed_frames2/S1/take_peanut/2',\n",
              " './GTEA61/processed_frames2/S1/take_spoon/1',\n",
              " './GTEA61/processed_frames2/S1/take_spoon/2',\n",
              " './GTEA61/processed_frames2/S1/take_spoon/3',\n",
              " './GTEA61/processed_frames2/S1/take_spoon/4',\n",
              " './GTEA61/processed_frames2/S1/take_spoon/5',\n",
              " './GTEA61/processed_frames2/S1/take_sugar/1',\n",
              " './GTEA61/processed_frames2/S1/take_sugar/2',\n",
              " './GTEA61/processed_frames2/S1/take_tea/1',\n",
              " './GTEA61/processed_frames2/S1/take_water/1',\n",
              " './GTEA61/processed_frames2/S1/take_water/2',\n",
              " './GTEA61/processed_frames2/S1/take_water/3',\n",
              " './GTEA61/processed_frames2/S3/close_chocolate/1',\n",
              " './GTEA61/processed_frames2/S3/close_coffee/1',\n",
              " './GTEA61/processed_frames2/S3/close_coffee/2',\n",
              " './GTEA61/processed_frames2/S3/close_honey/1',\n",
              " './GTEA61/processed_frames2/S3/close_honey/2',\n",
              " './GTEA61/processed_frames2/S3/close_jam/1',\n",
              " './GTEA61/processed_frames2/S3/close_ketchup/1',\n",
              " './GTEA61/processed_frames2/S3/close_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S3/close_mustard/1',\n",
              " './GTEA61/processed_frames2/S3/close_mustard/2',\n",
              " './GTEA61/processed_frames2/S3/close_peanut/1',\n",
              " './GTEA61/processed_frames2/S3/close_peanut/2',\n",
              " './GTEA61/processed_frames2/S3/close_sugar/1',\n",
              " './GTEA61/processed_frames2/S3/close_sugar/2',\n",
              " './GTEA61/processed_frames2/S3/close_water/1',\n",
              " './GTEA61/processed_frames2/S3/close_water/2',\n",
              " './GTEA61/processed_frames2/S3/close_water/3',\n",
              " './GTEA61/processed_frames2/S3/fold_bread/1',\n",
              " './GTEA61/processed_frames2/S3/open_cheese/1',\n",
              " './GTEA61/processed_frames2/S3/open_chocolate/1',\n",
              " './GTEA61/processed_frames2/S3/open_coffee/1',\n",
              " './GTEA61/processed_frames2/S3/open_coffee/2',\n",
              " './GTEA61/processed_frames2/S3/open_honey/1',\n",
              " './GTEA61/processed_frames2/S3/open_honey/2',\n",
              " './GTEA61/processed_frames2/S3/open_jam/1',\n",
              " './GTEA61/processed_frames2/S3/open_ketchup/1',\n",
              " './GTEA61/processed_frames2/S3/open_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S3/open_mustard/1',\n",
              " './GTEA61/processed_frames2/S3/open_mustard/2',\n",
              " './GTEA61/processed_frames2/S3/open_peanut/1',\n",
              " './GTEA61/processed_frames2/S3/open_peanut/2',\n",
              " './GTEA61/processed_frames2/S3/open_sugar/1',\n",
              " './GTEA61/processed_frames2/S3/open_sugar/2',\n",
              " './GTEA61/processed_frames2/S3/open_tea/1',\n",
              " './GTEA61/processed_frames2/S3/open_water/1',\n",
              " './GTEA61/processed_frames2/S3/open_water/2',\n",
              " './GTEA61/processed_frames2/S3/open_water/3',\n",
              " './GTEA61/processed_frames2/S3/pour_chocolate,bread/1',\n",
              " './GTEA61/processed_frames2/S3/pour_coffee,spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S3/pour_coffee,spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S3/pour_coffee,spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S3/pour_coffee,spoon,cup/4',\n",
              " './GTEA61/processed_frames2/S3/pour_honey,bread/1',\n",
              " './GTEA61/processed_frames2/S3/pour_honey,cup/1',\n",
              " './GTEA61/processed_frames2/S3/pour_ketchup,hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S3/pour_mayonnaise,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S3/pour_mustard,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S3/pour_mustard,hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S3/pour_sugar,spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S3/pour_sugar,spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S3/pour_sugar,spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S3/pour_sugar,spoon,cup/4',\n",
              " './GTEA61/processed_frames2/S3/pour_water,cup/1',\n",
              " './GTEA61/processed_frames2/S3/pour_water,cup/2',\n",
              " './GTEA61/processed_frames2/S3/pour_water,cup/3',\n",
              " './GTEA61/processed_frames2/S3/put_bread,bread/1',\n",
              " './GTEA61/processed_frames2/S3/put_bread,bread/2',\n",
              " './GTEA61/processed_frames2/S3/put_bread,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S3/put_cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S3/put_hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S3/scoop_coffee,spoon/1',\n",
              " './GTEA61/processed_frames2/S3/scoop_coffee,spoon/2',\n",
              " './GTEA61/processed_frames2/S3/scoop_coffee,spoon/3',\n",
              " './GTEA61/processed_frames2/S3/scoop_coffee,spoon/4',\n",
              " './GTEA61/processed_frames2/S3/scoop_jam,spoon/1',\n",
              " './GTEA61/processed_frames2/S3/scoop_peanut,spoon/1',\n",
              " './GTEA61/processed_frames2/S3/scoop_peanut,spoon/2',\n",
              " './GTEA61/processed_frames2/S3/scoop_sugar,spoon/1',\n",
              " './GTEA61/processed_frames2/S3/scoop_sugar,spoon/2',\n",
              " './GTEA61/processed_frames2/S3/scoop_sugar,spoon/3',\n",
              " './GTEA61/processed_frames2/S3/scoop_sugar,spoon/4',\n",
              " './GTEA61/processed_frames2/S3/shake_tea,cup/1',\n",
              " './GTEA61/processed_frames2/S3/spread_jam,spoon,bread/1',\n",
              " './GTEA61/processed_frames2/S3/spread_peanut,spoon,bread/1',\n",
              " './GTEA61/processed_frames2/S3/spread_peanut,spoon,bread/2',\n",
              " './GTEA61/processed_frames2/S3/stir_spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S3/stir_spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S3/stir_spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S3/take_bread/1',\n",
              " './GTEA61/processed_frames2/S3/take_bread/2',\n",
              " './GTEA61/processed_frames2/S3/take_bread/3',\n",
              " './GTEA61/processed_frames2/S3/take_bread/4',\n",
              " './GTEA61/processed_frames2/S3/take_bread/5',\n",
              " './GTEA61/processed_frames2/S3/take_bread/6',\n",
              " './GTEA61/processed_frames2/S3/take_bread/7',\n",
              " './GTEA61/processed_frames2/S3/take_cheese/1',\n",
              " './GTEA61/processed_frames2/S3/take_chocolate/1',\n",
              " './GTEA61/processed_frames2/S3/take_coffee/1',\n",
              " './GTEA61/processed_frames2/S3/take_coffee/2',\n",
              " './GTEA61/processed_frames2/S3/take_cup/1',\n",
              " './GTEA61/processed_frames2/S3/take_cup/2',\n",
              " './GTEA61/processed_frames2/S3/take_cup/3',\n",
              " './GTEA61/processed_frames2/S3/take_honey/1',\n",
              " './GTEA61/processed_frames2/S3/take_honey/2',\n",
              " './GTEA61/processed_frames2/S3/take_hotdog/1',\n",
              " './GTEA61/processed_frames2/S3/take_jam/1',\n",
              " './GTEA61/processed_frames2/S3/take_ketchup/1',\n",
              " './GTEA61/processed_frames2/S3/take_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S3/take_mustard/1',\n",
              " './GTEA61/processed_frames2/S3/take_mustard/2',\n",
              " './GTEA61/processed_frames2/S3/take_peanut/1',\n",
              " './GTEA61/processed_frames2/S3/take_peanut/2',\n",
              " './GTEA61/processed_frames2/S3/take_spoon/1',\n",
              " './GTEA61/processed_frames2/S3/take_spoon/2',\n",
              " './GTEA61/processed_frames2/S3/take_spoon/3',\n",
              " './GTEA61/processed_frames2/S3/take_spoon/4',\n",
              " './GTEA61/processed_frames2/S3/take_spoon/5',\n",
              " './GTEA61/processed_frames2/S3/take_sugar/1',\n",
              " './GTEA61/processed_frames2/S3/take_sugar/2',\n",
              " './GTEA61/processed_frames2/S3/take_tea/1',\n",
              " './GTEA61/processed_frames2/S3/take_water/1',\n",
              " './GTEA61/processed_frames2/S3/take_water/2',\n",
              " './GTEA61/processed_frames2/S3/take_water/3',\n",
              " './GTEA61/processed_frames2/S4/close_chocolate/1',\n",
              " './GTEA61/processed_frames2/S4/close_coffee/1',\n",
              " './GTEA61/processed_frames2/S4/close_coffee/2',\n",
              " './GTEA61/processed_frames2/S4/close_honey/1',\n",
              " './GTEA61/processed_frames2/S4/close_honey/2',\n",
              " './GTEA61/processed_frames2/S4/close_jam/1',\n",
              " './GTEA61/processed_frames2/S4/close_ketchup/1',\n",
              " './GTEA61/processed_frames2/S4/close_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S4/close_mustard/1',\n",
              " './GTEA61/processed_frames2/S4/close_mustard/2',\n",
              " './GTEA61/processed_frames2/S4/close_peanut/1',\n",
              " './GTEA61/processed_frames2/S4/close_peanut/2',\n",
              " './GTEA61/processed_frames2/S4/close_sugar/1',\n",
              " './GTEA61/processed_frames2/S4/close_sugar/2',\n",
              " './GTEA61/processed_frames2/S4/close_water/1',\n",
              " './GTEA61/processed_frames2/S4/close_water/2',\n",
              " './GTEA61/processed_frames2/S4/fold_bread/1',\n",
              " './GTEA61/processed_frames2/S4/open_cheese/1',\n",
              " './GTEA61/processed_frames2/S4/open_chocolate/1',\n",
              " './GTEA61/processed_frames2/S4/open_coffee/1',\n",
              " './GTEA61/processed_frames2/S4/open_coffee/2',\n",
              " './GTEA61/processed_frames2/S4/open_honey/1',\n",
              " './GTEA61/processed_frames2/S4/open_honey/2',\n",
              " './GTEA61/processed_frames2/S4/open_jam/1',\n",
              " './GTEA61/processed_frames2/S4/open_ketchup/1',\n",
              " './GTEA61/processed_frames2/S4/open_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S4/open_mustard/1',\n",
              " './GTEA61/processed_frames2/S4/open_mustard/2',\n",
              " './GTEA61/processed_frames2/S4/open_peanut/1',\n",
              " './GTEA61/processed_frames2/S4/open_peanut/2',\n",
              " './GTEA61/processed_frames2/S4/open_sugar/1',\n",
              " './GTEA61/processed_frames2/S4/open_sugar/2',\n",
              " './GTEA61/processed_frames2/S4/open_tea/1',\n",
              " './GTEA61/processed_frames2/S4/open_water/1',\n",
              " './GTEA61/processed_frames2/S4/open_water/2',\n",
              " './GTEA61/processed_frames2/S4/open_water/3',\n",
              " './GTEA61/processed_frames2/S4/pour_chocolate,bread/1',\n",
              " './GTEA61/processed_frames2/S4/pour_coffee,spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S4/pour_coffee,spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S4/pour_coffee,spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S4/pour_coffee,spoon,cup/4',\n",
              " './GTEA61/processed_frames2/S4/pour_honey,bread/1',\n",
              " './GTEA61/processed_frames2/S4/pour_honey,cup/1',\n",
              " './GTEA61/processed_frames2/S4/pour_ketchup,hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S4/pour_mayonnaise,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S4/pour_mustard,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S4/pour_mustard,hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S4/pour_sugar,spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S4/pour_sugar,spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S4/pour_sugar,spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S4/pour_water,cup/1',\n",
              " './GTEA61/processed_frames2/S4/pour_water,cup/2',\n",
              " './GTEA61/processed_frames2/S4/pour_water,cup/3',\n",
              " './GTEA61/processed_frames2/S4/put_bread,bread/1',\n",
              " './GTEA61/processed_frames2/S4/put_bread,bread/2',\n",
              " './GTEA61/processed_frames2/S4/put_bread,cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S4/put_cheese,bread/1',\n",
              " './GTEA61/processed_frames2/S4/put_hotdog,bread/1',\n",
              " './GTEA61/processed_frames2/S4/scoop_coffee,spoon/1',\n",
              " './GTEA61/processed_frames2/S4/scoop_coffee,spoon/2',\n",
              " './GTEA61/processed_frames2/S4/scoop_coffee,spoon/3',\n",
              " './GTEA61/processed_frames2/S4/scoop_coffee,spoon/4',\n",
              " './GTEA61/processed_frames2/S4/scoop_jam,spoon/1',\n",
              " './GTEA61/processed_frames2/S4/scoop_jam,spoon/2',\n",
              " './GTEA61/processed_frames2/S4/scoop_peanut,spoon/1',\n",
              " './GTEA61/processed_frames2/S4/scoop_peanut,spoon/2',\n",
              " './GTEA61/processed_frames2/S4/scoop_sugar,spoon/1',\n",
              " './GTEA61/processed_frames2/S4/scoop_sugar,spoon/2',\n",
              " './GTEA61/processed_frames2/S4/scoop_sugar,spoon/3',\n",
              " './GTEA61/processed_frames2/S4/shake_tea,cup/1',\n",
              " './GTEA61/processed_frames2/S4/spread_jam,spoon,bread/1',\n",
              " './GTEA61/processed_frames2/S4/spread_jam,spoon,bread/2',\n",
              " './GTEA61/processed_frames2/S4/spread_peanut,spoon,bread/1',\n",
              " './GTEA61/processed_frames2/S4/spread_peanut,spoon,bread/2',\n",
              " './GTEA61/processed_frames2/S4/spread_peanut,spoon,bread/3',\n",
              " './GTEA61/processed_frames2/S4/stir_spoon,cup/1',\n",
              " './GTEA61/processed_frames2/S4/stir_spoon,cup/2',\n",
              " './GTEA61/processed_frames2/S4/stir_spoon,cup/3',\n",
              " './GTEA61/processed_frames2/S4/stir_spoon,cup/4',\n",
              " './GTEA61/processed_frames2/S4/take_bread/1',\n",
              " './GTEA61/processed_frames2/S4/take_bread/2',\n",
              " './GTEA61/processed_frames2/S4/take_bread/3',\n",
              " './GTEA61/processed_frames2/S4/take_bread/4',\n",
              " './GTEA61/processed_frames2/S4/take_bread/5',\n",
              " './GTEA61/processed_frames2/S4/take_bread/6',\n",
              " './GTEA61/processed_frames2/S4/take_bread/7',\n",
              " './GTEA61/processed_frames2/S4/take_cheese/1',\n",
              " './GTEA61/processed_frames2/S4/take_chocolate/1',\n",
              " './GTEA61/processed_frames2/S4/take_coffee/1',\n",
              " './GTEA61/processed_frames2/S4/take_coffee/2',\n",
              " './GTEA61/processed_frames2/S4/take_cup/1',\n",
              " './GTEA61/processed_frames2/S4/take_cup/2',\n",
              " './GTEA61/processed_frames2/S4/take_cup/3',\n",
              " './GTEA61/processed_frames2/S4/take_honey/1',\n",
              " './GTEA61/processed_frames2/S4/take_honey/2',\n",
              " './GTEA61/processed_frames2/S4/take_hotdog/1',\n",
              " './GTEA61/processed_frames2/S4/take_jam/1',\n",
              " './GTEA61/processed_frames2/S4/take_ketchup/1',\n",
              " './GTEA61/processed_frames2/S4/take_mayonnaise/1',\n",
              " './GTEA61/processed_frames2/S4/take_mustard/1',\n",
              " './GTEA61/processed_frames2/S4/take_mustard/2',\n",
              " './GTEA61/processed_frames2/S4/take_peanut/1',\n",
              " './GTEA61/processed_frames2/S4/take_peanut/2',\n",
              " './GTEA61/processed_frames2/S4/take_spoon/1',\n",
              " './GTEA61/processed_frames2/S4/take_spoon/2',\n",
              " './GTEA61/processed_frames2/S4/take_spoon/3',\n",
              " './GTEA61/processed_frames2/S4/take_spoon/4',\n",
              " './GTEA61/processed_frames2/S4/take_spoon/5',\n",
              " './GTEA61/processed_frames2/S4/take_sugar/1',\n",
              " './GTEA61/processed_frames2/S4/take_sugar/2',\n",
              " './GTEA61/processed_frames2/S4/take_tea/1',\n",
              " './GTEA61/processed_frames2/S4/take_water/1',\n",
              " './GTEA61/processed_frames2/S4/take_water/2',\n",
              " './GTEA61/processed_frames2/S4/take_water/3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-VN9uAqGOMp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}