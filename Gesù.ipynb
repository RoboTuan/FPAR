{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gesù.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e730ae419bc446a8a3264a170d49be50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3fa63c1d68a343e2ba3274ffc2310c4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ddd99135abe41109e9c8101a190533d",
              "IPY_MODEL_233cbbb6abd749ef8240b118868ebc3e"
            ]
          }
        },
        "3fa63c1d68a343e2ba3274ffc2310c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ddd99135abe41109e9c8101a190533d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3539594cffcf4d2587b44c26d20f1c96",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_310a686b30b54c1aa821c2e06df8d0bd"
          }
        },
        "233cbbb6abd749ef8240b118868ebc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc8cc4eea8a542b49de266c5f04222ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:15&lt;00:00, 5.77MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_978132f8a2234ac993db7ba66fcb05f4"
          }
        },
        "3539594cffcf4d2587b44c26d20f1c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "310a686b30b54c1aa821c2e06df8d0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc8cc4eea8a542b49de266c5f04222ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "978132f8a2234ac993db7ba66fcb05f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboTuan/ML_DL_Project/blob/master/Ges%C3%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLYoVb2SQnG0",
        "cellView": "both",
        "outputId": "948e714e-4c7d-4b02-94a8-478ab23ec1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#@title\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.autograd import Function\n",
        "import torchvision\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import pandas.util.testing as tm\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZVmFAwkQ0AS",
        "outputId": "7c29f942-058b-44c6-861c-5f5f68d1d1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzqpeOqKQ0Vt"
      },
      "source": [
        "!unzip -q \"./drive/My Drive/Copia di GTEA61.zip\"\n",
        "!rm -rf \"./__MACOSX\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihz9gTQEQ0Z3"
      },
      "source": [
        "!rm -rf \"./ML_DL_Project/\"\n",
        "#!rm -rf \"./out_dir/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKvNku7pQ0cp",
        "outputId": "c413b752-b2c5-4d7d-c77d-f844d52da920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import os \n",
        "if not os.path.isdir('./ML_DL_Project'):\n",
        "  !git clone https://github.com/RoboTuan/ML_DL_Project.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_DL_Project'...\n",
            "remote: Enumerating objects: 136, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 366 (delta 92), reused 77 (delta 43), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (366/366), 89.24 MiB | 14.92 MiB/s, done.\n",
            "Resolving deltas: 100% (226/226), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-6YG3acQ0g3",
        "outputId": "99df2313-c6b7-4bcc-b756-734112a29ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "base_dataset = \"./GTEA61\"\n",
        "\n",
        "if not os.path.isdir('./GTEA61_val'):\n",
        "  os.makedirs(\"./GTEA61_val\")\n",
        "  os.makedirs(\"./GTEA61_val/flow_x_processed\")\n",
        "  os.makedirs(\"./GTEA61_val/flow_y_processed\")\n",
        "  os.makedirs(\"./GTEA61_val/processed_frames2\")\n",
        "  pass\n",
        "\n",
        "\n",
        "for directory in sorted(os.listdir(base_dataset)):\n",
        "  if not directory.startswith('.'):\n",
        "    directory_path = os.path.join(base_dataset, directory)\n",
        "    new_directory_path = os.path.join(\"./GTEA61_val\", directory)\n",
        "\n",
        "    for user in sorted(os.listdir(directory_path)):\n",
        "      if not user.startswith('.') and user == \"S2\":\n",
        "        current_folder = os.path.join(directory_path, user)\n",
        "        !cp -r \"{current_folder}\" \"{new_directory_path}\"\n",
        "        !rm -rf \"{current_folder}\"\n",
        "        print(current_folder)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./GTEA61/flow_x_processed/S2\n",
            "./GTEA61/flow_y_processed/S2\n",
            "./GTEA61/processed_frames2/S2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nepLRofOQ0ji"
      },
      "source": [
        "# Se scritti uguali ai parametri della funzione può venire None come risultato\n",
        "# per questo SEQLEN è maiuscolo \n",
        "SEQLEN = 7\n",
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "num_classes = 61\n",
        "#STAGE = None\n",
        "train_data_dir = \"./GTEA61\"\n",
        "val_data_dir = \"./GTEA61_val\"\n",
        "#stage1_dict = None\n",
        "outDir = \".out_dir\"\n",
        "trainBatchSize = 32\n",
        "valBatchSize = 64\n",
        "numEpochs1 = 3\n",
        "numEpochs2 = 3\n",
        "lr1 = 1e-3\n",
        "lr2 = 1e-4\n",
        "decay_factor = 0.1\n",
        "decay_step1 = [25, 75, 150]\n",
        "decay_step2 = [25, 75]\n",
        "#Boh?!\n",
        "memSize = 512\n",
        "alpha=1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZoYPO1hQ0o5"
      },
      "source": [
        "#!rm -rf \"ML_DL_Project\"\n",
        "#!rm -rf \"./GTEA61\"\n",
        "#!rm -rf \"./GTEA61_val\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrGDU3ojQ0uu"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "# This is without attention, we must address this better\n",
        "#from ML_DL_Project.Scripts.convLSTMmodel import *\n",
        "from ML_DL_Project.Scripts.SelfSupObjectAttentionModelConvLSTM import *\n",
        "#from ML_DL_Project.Scripts.RegObjectAttentionModelConvLSTM import *\n",
        "from ML_DL_Project.Scripts.spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from ML_DL_Project.Scripts.resnetMod import *\n",
        "#from ML_DL_Project.Scripts.makeDatasetRGB import *\n",
        "from ML_DL_Project.Scripts.makeMmaps import *\n",
        "#Prende il makeDataset dell'ultimo script importato\n",
        "import argparse\n",
        "import sys"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec7hvOY2UjYG"
      },
      "source": [
        "!rm -rf \"./out_dir\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51H5bheaAx2I"
      },
      "source": [
        "# Data loader\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256),\n",
        "                             RandomHorizontalFlip(), \n",
        "                             MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), \n",
        "                             normalize])\n",
        "\n",
        "vid_seq_train = makeDataset(train_data_dir, spatial_transform=spatial_transform, seqLen=SEQLEN, fmt='.png')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "if val_data_dir is not None:\n",
        "  vid_seq_val = makeDataset(val_data_dir,spatial_transform = Compose([Scale(256),\n",
        "                                                                    CenterCrop(224),\n",
        "                                                                    ToTensor(),\n",
        "                                                                    normalize]),\n",
        "                            seqLen=SEQLEN, fmt='.png')\n",
        "\n",
        "  val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize, shuffle=False, num_workers=2, pin_memory=True)\n",
        "  valInstances = vid_seq_val.__len__()\n",
        "\n",
        "\n",
        "trainInstances = vid_seq_train.__len__()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFrMnCz_A8Al",
        "outputId": "0be54795-6cca-414c-f7e2-569ec47ce09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for seqImages, seqMaps, labels in train_loader:\n",
        "  print(f\"Batch size: {len(seqImages)}\")\n",
        "  #Make dataset restituisce una sequenza di immagini e di mappe\n",
        "  print(f\"Batch size: {len(seqMaps)}\")\n",
        "  print(f\"Number of frames selected: {len(seqImages[0])}\")\n",
        "  print(f\"Number of frames selected maps: {len(seqMaps[0])}\")\n",
        "\n",
        "  break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch size: 32\n",
            "Batch size: 32\n",
            "Number of frames selected: 7\n",
            "Number of frames selected maps: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-E6m3-D6IzN"
      },
      "source": [
        "\n",
        "model_folder = os.path.join('./', outDir, \"GTEA61\", 'selfSup')\n",
        "#model_folder = os.path.join('./', \"out_dir\", \"./GTEA61\", 'rgb')\n",
        "if os.path.exists(model_folder):\n",
        "    print('Dir {} exists!'.format(model_folder))\n",
        "    sys.exit()\n",
        "os.makedirs(model_folder)\n",
        "\n",
        "# Log files\n",
        "writer = SummaryWriter(model_folder)\n",
        "train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n",
        "train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n",
        "val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n",
        "val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnsYtNDOC4Mi",
        "outputId": "d3647bfc-5ef9-4ef1-e5ae-bf7889d02e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "e730ae419bc446a8a3264a170d49be50",
            "3fa63c1d68a343e2ba3274ffc2310c4c",
            "0ddd99135abe41109e9c8101a190533d",
            "233cbbb6abd749ef8240b118868ebc3e",
            "3539594cffcf4d2587b44c26d20f1c96",
            "310a686b30b54c1aa821c2e06df8d0bd",
            "bc8cc4eea8a542b49de266c5f04222ca",
            "978132f8a2234ac993db7ba66fcb05f4"
          ]
        }
      },
      "source": [
        "train_params = []\n",
        "model = attentionModel(num_classes=num_classes, mem_size=memSize)\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "for params in model.lstm_cell.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "model.lstm_cell.train(True)\n",
        "\n",
        "model.classifier.train(True)\n",
        "model.cuda()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n",
        "\n",
        "optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step1,\n",
        "                                                           gamma=decay_factor)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e730ae419bc446a8a3264a170d49be50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoGca_3i-h7n",
        "outputId": "3feec93b-f057-4105-dd26-8e25fe10dbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "valDatasetDir = val_data_dir\n",
        "\n",
        "train_iter = 0\n",
        "min_accuracy = 0\n",
        "for epoch in range(numEpochs1):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    mmap_loss = 0\n",
        "    trainSamples = 0\n",
        "    iterPerEpoch = 0\n",
        "    \n",
        "    model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    #for i, (inputs, targets) in enumerate(train_loader):\n",
        "    for inputs, inputMmap, targets in train_loader:\n",
        "        train_iter += 1\n",
        "        iterPerEpoch += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "\n",
        "        inputMmap = inputMmap.cuda()\n",
        "        \n",
        "        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "        labelVariable = Variable(targets.cuda())\n",
        "        trainSamples += inputs.size(0)\n",
        "        \n",
        "        output_label, _ , mmapPrediction = model(inputVariable)\n",
        "\n",
        "        mmapPrediction = mmapPrediction.view(-1,2)         \n",
        "        inputMmap = torch.reshape(inputMmap, (-1,)) #.long()\n",
        "        inputMmap = torch.round(inputMmap).long() #making things black and white again\n",
        "        \n",
        "        \n",
        "        #print(mmapPrediction.size())\n",
        "        #print(inputMmap.size())\n",
        "        #print(mmapPrediction)\n",
        "        #print(inputMmap)\n",
        "        #sys.exit()\n",
        "\n",
        "        loss_reg = alpha*loss_fn(mmapPrediction,inputMmap)\n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        #Weighting the loss of the ss task\n",
        "        #by multiplying it by alpha\n",
        "        total_loss = loss  + loss2\n",
        "        total_loss.backward()\n",
        "        \n",
        "        optimizer_fn.step()\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += (predicted == targets.cuda()).sum()\n",
        "        mmap_loss += loss2.item()\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "    avg_mmap_loss = mmap_loss / iterPerEpoch\n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = torch.true_divide(numCorrTrain , trainSamples) * 100\n",
        "    \n",
        "    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n",
        "    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n",
        "    train_log_loss.write('Training loss after {} epoch = {}\\n'.format(epoch+1, avg_loss))\n",
        "    train_log_acc.write('Training accuracy after {} epoch = {}\\n'.format(epoch+1, trainAccuracy))\n",
        "\n",
        "    print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    print('Mmap loss after {} epoch = {} '.format(epoch + 1, avg_mmap_loss))\n",
        "\n",
        "    \n",
        "    if valDatasetDir is not None:\n",
        "        model.train(False)\n",
        "        val_loss_epoch = 0\n",
        "        val_iter = 0\n",
        "        val_mmap_loss = 0\n",
        "        val_samples = 0\n",
        "        numCorr = 0\n",
        "        mmap_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #for j, (inputs, targets) in enumerate(val_loader):\n",
        "            for inputs, inputMmap, targets in val_loader:\n",
        "                val_iter += 1\n",
        "                val_samples += inputs.size(0)\n",
        "                inputMmap = inputMmap.cuda()\n",
        "\n",
        "                \n",
        "                inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "                labelVariable = Variable(targets.cuda(async=True))\n",
        "                #labelVariable = Variable(targets.cuda())\n",
        "                \n",
        "                output_label, _ , mmapPrediction = model(inputVariable)\n",
        "\n",
        "                mmapPrediction = mmapPrediction.view(-1,2)\n",
        "                inputMmap = torch.reshape(inputMmap, (-1,)) #.long()\n",
        "                inputMmap = torch.round(inputMmap).long()\n",
        "                loss2 = alpha*loss_fn(mmapPrediction,inputMmap)\n",
        "\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_epoch += val_loss.item()\n",
        "                val_mmap_loss += loss2.item()\n",
        "                \n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += (predicted == targets.cuda()).sum()\n",
        "\n",
        "        avg_mmap_val_loss = val_mmap_loss / val_iter\n",
        "        val_accuracy = torch.true_divide(numCorr , val_samples) * 100\n",
        "        avg_val_loss = val_loss_epoch / val_iter\n",
        "        \n",
        "        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n",
        "        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n",
        "        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n",
        "        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n",
        "\n",
        "        print('Val MMap Loss after {} epochs, loss = {}'.format(epoch + 1, avg_mmap_val_loss))\n",
        "        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "\n",
        "        if val_accuracy > min_accuracy:\n",
        "            save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n",
        "            torch.save(model.state_dict(), save_path_model)\n",
        "            min_accuracy = val_accuracy\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: Epoch = 1 | Loss = 3.843002514405684 | Accuracy = 8.797654151916504\n",
            "Mmap loss after 1 epoch = 0.8008179068565369 \n",
            "Val MMap Loss after 1 epochs, loss = 0.8123058676719666\n",
            "Val: Epoch = 1 | Loss 3.693465828895569 | Accuracy = 9.482758522033691\n",
            "Train: Epoch = 2 | Loss = 3.7302194291895088 | Accuracy = 10.85044002532959\n",
            "Mmap loss after 2 epoch = 0.8008179068565369 \n",
            "Val MMap Loss after 2 epochs, loss = 0.8123058676719666\n",
            "Val: Epoch = 2 | Loss 3.5182019472122192 | Accuracy = 12.068964958190918\n",
            "Train: Epoch = 3 | Loss = 3.6424417278983374 | Accuracy = 9.970674514770508\n",
            "Mmap loss after 3 epoch = 0.8008179068565369 \n",
            "Val MMap Loss after 3 epochs, loss = 0.8123058676719666\n",
            "Val: Epoch = 3 | Loss 3.5622751712799072 | Accuracy = 11.206896781921387\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}